{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление:\n",
    "* [1 Описание данных](#One)\n",
    "* [2 Загрузка и подготовка данных](#Two)\n",
    "* [3 Обучение моделей](#Three)\n",
    "* [4 Проверка на адекватность](#Four)\n",
    "* [5 Общий вывод](#Five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи:\n",
    "Нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "## 1 Описание данных <a class=\"anchor\" id=\"One\"></a>\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для решения задачи использовалась модель BERT-bert-base-uncased, English https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Загрузка и подготовка данных <a class=\"anchor\" id=\"Two\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import gc\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для уменьшения объема используемой памяти приведем целевой признак к типу int8\n",
    "df['toxic'] = df['toxic'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведем текст датасета к нижнему регистру\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизируем текст при помощи BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "#tokenizer = transformers.AlbertTokenizer.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценим максимальную длину токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(map(len, tokenized))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В датасете имеются очень длинные токены, модель BERT требует использовать токены менее длиной менее 512. Исключим из датасета длинные токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из датасета необходимо удалить 3523 значений\n"
     ]
    }
   ],
   "source": [
    "len_tok = tokenized.apply(lambda x: len(x))\n",
    "print('Из датасета необходимо удалить',len_tok[len_tok>512].count(), 'значений')\n",
    "index_to_drop = len_tok[len_tok>512].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index_to_drop).reset_index(drop=True)\n",
    "tokenized = tokenized.drop(index_to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n",
       "1         [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n",
       "2         [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n",
       "3         [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n",
       "4         [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n",
       "                                ...                        \n",
       "156043    [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...\n",
       "156044    [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...\n",
       "156045    [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...\n",
       "156046    [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...\n",
       "156047    [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...\n",
       "Name: text, Length: 156048, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выделим целевой признак и удалим из памяти датасет, для уменьшения объема требуемой памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим сбалансированность классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    140169\n",
       "1     15879\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выборка не сбалансирована. Для ускорения обучения моделей и улучшения предсказаний необходимо будет провести downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(features, target, fraction):\n",
    "    \"\"\"\n",
    "    Функция проводит downsampling выборки (признаков с целевым признаком равным 0)\n",
    "    На выходе дает перемешанные признаки и целевой признак. Для удобства, индексы будут сброшены\n",
    "    \"\"\"\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled.reset_index(drop=True), target_downsampled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проведем downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_downsampled, target_downsampled = downsampling(tokenized, target, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удалим более не нужные серии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим максимальную длину токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(map(len, tokenized_downsampled))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавим нули к токенам длиной меньшим чем max_len, чтобы преобразовать токены в вектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros(x):\n",
    "    \"\"\"\n",
    "    Функция добавляет нули к строкам массива меньшим по длинне чем max_len\n",
    "    \"\"\"\n",
    "    x = np.array(x + [0]*(max_len - len(x)), dtype='int16')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_downsampled = tokenized_downsampled.apply(add_zeros).to_numpy()\n",
    "\n",
    "padded = np.zeros((len(tokenized_downsampled), len(tokenized_downsampled[0])), dtype='int16' )\n",
    "\n",
    "for i in range(len(tokenized_downsampled)):\n",
    "    padded[i,:] = tokenized_downsampled[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим маску"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask = attention_mask.astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выберем модель для эмбеддинга, конфигурация модели - по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "#model = transformers.AlbertForMaskedLM.from_pretrained('albert-base-v2')\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36904, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36904, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для эмбеддинга будем использовать GPU, если это возможно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для освобождения памяти перед обучением запустим сборщик мусора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим эмбеддинги. Создание на локальной машине заняло 1 час 10 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b7dbd0b9d3471591b06cedfe661b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1845.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // (batch_size))):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удалим ненужные более массивы и запустим сборщик мусора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del padded, attention_mask\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выделим признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36900, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36904,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Размерности матрицы признаков и матрицы целевого признака отличаются ввиду цпецифики проведения эмбеддинга, исключим из матрицы целевого признака лишние значения с конца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(0, features.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_downsampled = target_downsampled[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36900,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделим выборку на тренировочную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, \n",
    "    target_downsampled, \n",
    "    test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Мы будем проводить обучение методом кросс-валидации, поэтому выделение отдельно валидационной выборки не нужно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы \n",
    "    1. Данные загружены и проанализированы.\n",
    "    2. Целевой признак приведен к типу int8, для уменьшения затрат ресурсов.\n",
    "    3. Текст приведен к нижнему регистру.\n",
    "    4. Текст токенизирован при помощи BertTokenizerFast.\n",
    "    5. Из датасета исключены векторы длинной больше 512.\n",
    "    6. Выборка сбалансирована методом downsampling.\n",
    "    7. Сформированы векторы равной длины (padded) и маска признаков.\n",
    "    8. При помощи BertModel проведен эмбеддинг ткстов.\n",
    "    9. Выборка разделена на тренировочную и тестовую.\n",
    "    10. Данные готовы к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Обучение моделей <a class=\"anchor\" id=\"Three\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение будем проводить моделями логистической регрессии, дерева решений, случайного леса и бэггинга решающих деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr_val_sc(model, features, target):\n",
    "    \"\"\"\n",
    "    Функция проводит кросс-валидацию и считает среднюю метрику\n",
    "    \"\"\"\n",
    "    score = cross_val_score(model, features, target, cv=5, scoring = 'f1')\n",
    "    final_score = score.mean()\n",
    "    return print('Величина f1-score по результатам кросс-валидации составила: ',final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression(solver='sag')\n",
    "model_forest = RandomForestClassifier(random_state=12345, n_jobs=-1)\n",
    "model_tree =  DecisionTreeClassifier(random_state=12345)\n",
    "model_bagging = BaggingClassifier(random_state=12345, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кросс-валидация модели Логистической Регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Величина f1-score по результатам кросс-валидации составила:  0.8755172062749829\n"
     ]
    }
   ],
   "source": [
    "cr_val_sc(model_logistic, features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Зададим параметры для кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_forest = {\n",
    "    'n_estimators': list(range(50,300,50)),\n",
    "    'max_depth':[5,15],\n",
    "    'max_features' : list(range(1,20, 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 100, 150, 200, 250]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim = list(range(50, 300, 50))\n",
    "estim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tree = {   \n",
    "    'max_depth':list(range(1,20))  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bagging ={\n",
    "    'n_estimators': list(range(50,300,50)),\n",
    "    'max_features' : list(range(1,20)),     \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели решающих деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=12345,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None, param_grid={'max_depth': [1, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_tree = GridSearchCV(model_tree, \n",
    "                       param_grid=params_tree, \n",
    "                       scoring = 'f1', cv=5)\n",
    "\n",
    "CV_tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение f1_score: 0.7160962760727237\n",
      "С параметром {'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "print('Лучшее значение f1_score:', CV_tree.best_score_)\n",
    "print('С параметром', CV_tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=12345, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [5, 15], 'max_features': [1, 20, 2],\n",
       "                         'n_estimators': [50, 300, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_forest = GridSearchCV(model_forest, \n",
    "                         param_grid=params_forest, \n",
    "                         scoring='f1', \n",
    "                         cv=5)\n",
    "\n",
    "CV_forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение f1_score: 0.8271542106517517\n",
      "С параметром {'max_depth': 15, 'max_features': 20, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print('Лучшее значение f1_score:', CV_forest.best_score_)\n",
    "print('С параметром', CV_forest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели Бэггинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "                                         bootstrap_features=False,\n",
       "                                         max_features=1.0, max_samples=1.0,\n",
       "                                         n_estimators=10, n_jobs=-1,\n",
       "                                         oob_score=False, random_state=12345,\n",
       "                                         verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_features': [1, 20],\n",
       "                         'n_estimators': [50, 300, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_bagging = GridSearchCV(model_bagging, \n",
    "                          param_grid=params_bagging, \n",
    "                          scoring= 'f1', \n",
    "                          cv=5)\n",
    "CV_bagging.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение f1_score: 0.80120621757899\n",
      "С параметром {'max_features': 20, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print('Лучшее значение f1_score:', CV_bagging.best_score_)\n",
    "print('С параметром', CV_bagging.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лучшие результаты показала модель логистической регрессии, обучим её и проверим на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score для тренировочной выборки составил  0.8916591115140525\n"
     ]
    }
   ],
   "source": [
    "prediction_train = model_final.predict(features_train)\n",
    "print('f1_score для тренировочной выборки составил ', f1_score(target_train, prediction_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score для тестовой выборки составил  0.8761258874642366\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model_final.predict(features_test)\n",
    "print('f1_score для тестовой выборки составил ', f1_score(target_test, prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы \n",
    "    1. Для решения задачи были использованы модели логистической регрессии, случайного леса, дерева решений и бэггинга.\n",
    "    2. Проведена кросс-валидация результатов предсказаний.\n",
    "    3. Для моделей подобраны наилучшие параметры.\n",
    "    4. Наилучшие результаты показала логистическая регрессия со средним результатом f1_score = 0,875.\n",
    "    5. Наилучшая модель обучена на тренировочной выборке.\n",
    "    6. F1_score на тестовой выборке показал результат 0,876."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Проверка на адекватность <a class=\"anchor\" id=\"Four\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проведем проверку на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "model_dummy = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score для Dummy модели составил  0.43100189035916825\n"
     ]
    }
   ],
   "source": [
    "model_dummy.fit(features_train, target_train)\n",
    "prediction_dummy = model_dummy.predict(features_test)\n",
    "print('f1_score для Dummy модели составил ', f1_score(target_test, prediction_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Общий вывод <a class=\"anchor\" id=\"Five\"></a>\n",
    "    1. В ходе работы были проведена предобработка исходного датасета средствами BERT модели.\n",
    "    2. Для обучения были выбраны модели LogisticRegression, RandomForest, DescissionTree, Bagging.\n",
    "    3. Был проведен подбор наилучших параметров и кросс-валидация моделей на тренировочной выборке.\n",
    "    4. Кросс-валидация показала следующие результаты f1_score на тренировочной выборке:\n",
    "        - LogisticRegression - 0.875\n",
    "        - RandomForest - 0.827\n",
    "        - DescissionTree - 0.716\n",
    "        - Bagging - 0.8\n",
    "    5. Все модели кроме решающих деревьев показали результаты лучше заданных - более 0.75.\n",
    "    6. Проверка модели на адекватность при помощи DummyClassifier прошла успешно. f1_score для DUmyy модели - 0.43.\n",
    "    7. Лучшая модель LogisticRegression на тестовой выборке показала результат f1_score = 0.876."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
